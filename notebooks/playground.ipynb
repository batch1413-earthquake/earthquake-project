{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Earthquake API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2023-10-01\"\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query?\"\n",
    "\n",
    "date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "yesterday = date - relativedelta(days=1)\n",
    "\n",
    "query_params = {\n",
    "    'starttime': yesterday.replace(day=1),\n",
    "    'endtime': yesterday,\n",
    "    'format': 'geojson',\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, params=query_params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "    else:\n",
    "        print(f\"Request failed with status code: {response.status_code}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write and Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"geojson_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(response_json, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_json\n",
    "with open(\"geojson_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    geojson_json = json.load(f)\n",
    "\n",
    "geojson_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(response_json[\"features\"])\n",
    "df.columns\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"geojson_data.json\", \"r\") as f:\n",
    "    df = pd.json_normalize(json.load(f)[\"features\"])\n",
    "renaming = {'properties.mag': 'properties_magnitude',\n",
    "'properties.place':  'properties_place',\n",
    "'properties.time':  'properties_time',\n",
    "'properties.updated':  'properties_updated',\n",
    "'properties.felt':  'properties_felt_count',\n",
    "'properties.alert':  'properties_alert',\n",
    "'properties.status':  'properties_status',\n",
    "'properties.tsunami':  'properties_tsunami',\n",
    "'properties.sig':  'properties_significance',\n",
    "'properties.nst':  'properties_seismic_station_count',\n",
    "'properties.type':  'properties_type',\n",
    "'properties.title':  'properties_title'}\n",
    "df.rename(columns=renaming, inplace=True)\n",
    "df.columns\n",
    "def split_coordinates(row: pd.Series):\n",
    "    coordinates = row['geometry.coordinates']\n",
    "    row['longitude'] = coordinates[0]\n",
    "    row['latitude'] = coordinates[1]\n",
    "    row['elevation'] = coordinates[2]\n",
    "    return row\n",
    "\n",
    "df = df.apply(split_coordinates, axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\".\".join(\"data/toto.geojson_data.json\".split(\".\")[:-1]) + \".parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open(\"geojson_data.json\", \"r\") as f:\n",
    "    df = pd.json_normalize(json.load(f)[\"features\"])\n",
    "\n",
    "df = pd.read_parquet(\"usgs_data-geojson_data_2022-12-31.parquet\")\n",
    "df.head()\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[['type', 'id', 'properties_magnitude', 'properties_place',\n",
    "            'properties_time', 'properties_updated',\n",
    "            'properties_felt_count', 'properties_alert',\n",
    "            'properties_status', 'properties_tsunami',\n",
    "            'properties_significance', 'properties_seismic_station_count',\n",
    "            'properties_type', 'properties_title', 'longitude', 'latitude', 'elevation']].columns) == len(df.columns)\n",
    "\n",
    "set(df[['type', 'id', 'properties_magnitude', 'properties_place',\n",
    "            'properties_time', 'properties_updated',\n",
    "            'properties_felt_count', 'properties_alert',\n",
    "            'properties_status', 'properties_tsunami',\n",
    "            'properties_significance', 'properties_seismic_station_count',\n",
    "            'properties_type', 'properties_title', 'longitude', 'latitude', 'elevation']].columns) - set(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df[\"properties_felt_count\"] = df[\"properties_felt_count\"].replace(np.nan, 0).astype(int)\n",
    "df[\"properties_felt_count\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "df.parallel_apply(split_coordinates, axis='columns')\n",
    "\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.utcfromtimestamp(1696031889550/1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(datetime.utcfromtimestamp(1577750367859/1000).replace(microsecond=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"properties_felt_count\"].astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "import pandas as pd\n",
    "import json\n",
    "with open(\"usgs_data-geojson_data_2022-11-30-bronze.json\", \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "        df = pd.json_normalize(json_data[\"features\"])\n",
    "\n",
    "df[\"properties.time\"].head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df[\"properties_time\"]/1000).astype('datetime64[s]')\n",
    "(df[\"properties.time\"]).astype('datetime64[ms]')\n",
    "pd.concat([df, pd.DataFrame(df[\"geometry.coordinates\"].tolist(), columns=[\"geo1\", \"geo2\", \"geo3\"])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetime.utcfromtimestamp(1669765859910/1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
